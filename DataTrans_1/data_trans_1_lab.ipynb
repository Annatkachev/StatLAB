{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89df1ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "from numpy.random import uniform\n",
    "from numpy.random import normal\n",
    "from numpy.random import exponential\n",
    "from numpy.random import lognormal\n",
    "\n",
    "from numpy.random import choice\n",
    "from numpy.random import permutation\n",
    "\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e28298b",
   "metadata": {},
   "source": [
    "## DATA TRANS 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d810fb7c",
   "metadata": {},
   "source": [
    "    1. \n",
    "    A. Consider the two random variable presented below, from dataset \"blooddf.csv\", which represents measurements of metabolites in the blood. Build a linear regression of y over x. Calculate the proportion of variance of y explained by x. Calculate the Pearson correlation coefficient, and state the relatioship betweent the two. Visualize the residuals of the model (diffference between y values and predicted values). Perform the analysis for both original data and log-transformed data, what difference do you get?\n",
    "    \n",
    "    B. Find the 1% of data points with largest abosulute residuals. If you remove these data points from the data, how much will the above calculated values change for the original data and log-transformed data?\n",
    "\n",
    "    \n",
    "    2. \n",
    "    Consider the \"proteins_SZL.csv\" dataset, which contains measurments of protein levels in the coritcal layers for two brain regions. The  \"proteins_samples_SZL.csv\" contains corresponing sample information. Perform a PCA analysis with 4 components, calculate the proportion of variance explained. Visualize the first and second PCA components in a scatter plot, and color the samples first by layer values, and also by region value. For which factor can you observe a substantial effect?\n",
    "    \n",
    "    For the first and second principal component, extract feature coefficients representing the PCA linear tranfsormation. Visualize their values, as well as their relationship with feature variance. Visualize the relationship between the PC1 and the feature with largest (absolute) weight in PC1 component, and do the same for PC2.\n",
    "    \n",
    "    \n",
    "    A. Perform analysis for both original data and log-transformed data. What is the difference in your results?\n",
    "    B. Consider the top 5 features with largest variance in the data. Perform a PCA analysis, visualize the first and second PCA components in a scatter plot. How did you first and second component change compared to analysis in A, for original data and log-transformed data?\n",
    "    C. For the original data. consider performing Z-score transformation on your features (by substracting the mean value of each feature and dividing by the standard deviation of the feature).Perform a PCA analysis, visualize the first and second PCA components in a scatter plot. Did the transformation improve the the visual separation of the samples by factors? Explain the difference the Z-score tranformation and log-transformation has on your data. \n",
    "    \n",
    "    \n",
    "    3. Consider the PCA analysis you performed in Q2 for log-transformed data. For PC2, calculate the proportion of variance explained by the variable \"L1_yesno\" (a binary variable of whether or not the layer is the first layer).\n",
    "    \n",
    "    4. \n",
    "    \n",
    "    A. Consider both dataset \"blooddf.csv\" and \"proteins_SZL.csv\". For both datasets, visualize the relationship between feature mean and feature variance. What does the relationship look like in the original scale, and log-transformed scale? What implication does this observation have for multivariate analysis that takes into account feature variance, such as PCA?\n",
    "    \n",
    "    \n",
    "    B. Use the dataset \"blooddf.csv\" and \"bloodsamples.csv\", which contains the corresponding sample information. Calculate the fold-change in feature values between men and women (i.e. the ratio of mean values for the original data), and the log2 fold-changes betweeen mean and women (i.e. the difference in mean values for log-transformed data). Visualize the relationship between fold-changes and log2 fold-changes. If you take the log2 of the fold-changes, do you get exactly the log2 fold-change? Explain, and visualize the relationship. \n",
    "    \n",
    "    Perform the same analysis for \"proteins_SZL.csv\",\"proteins_samples_SZL.csv\" dataset, and the difference between the layer L1 and the rest of the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f76d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path='https://raw.githubusercontent.com/Annatkachev/StatLAB/refs/heads/main/DataTrans_1/'\n",
    "path='/home/anna/PROJECTS2025/StatDatAnLAB/DataTrans/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e36ce10",
   "metadata": {},
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f56708",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(path+'blooddf.csv',index_col=0)\n",
    "samples=pd.read_csv(path+'bloodsamples.csv',index_col=0)\n",
    "\n",
    "df=data\n",
    "logdf=np.log2(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75bd6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['feature162']\n",
    "y=df['feature155']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7905515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=logdf['feature162']\n",
    "y=logdf['feature155']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4828c17",
   "metadata": {},
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c71a112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(path+'proteins_SZL.csv',index_col=0)\n",
    "samples=pd.read_csv(path+'proteins_samples_SZL.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b65cccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data\n",
    "logdf=np.log2(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be0eb4",
   "metadata": {},
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63835d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.loc[samples['Layer']=='L1','L1_yesno']=1\n",
    "samples.loc[samples['Layer']!='L1','L1_yesno']=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bc3963",
   "metadata": {},
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29578b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(path+'blooddf.csv',index_col=0)\n",
    "samples=pd.read_csv(path+'bloodsamples.csv',index_col=0)\n",
    "#data=pd.read_csv(path+'proteins_SZL.csv',index_col=0)\n",
    "#samples=pd.read_csv(path+'proteins_samples_SZL.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "798a602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data\n",
    "logdf=np.log2(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f4e686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5558ad94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
